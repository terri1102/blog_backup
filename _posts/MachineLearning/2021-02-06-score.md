---
layout: post
title: "[Machine Learning]모델의 성능을 평가하는 지표(범주 분류 모델)"
date: 2021-02-06
category: [Machine Learning]
MachineLearning : true 
excerpt: "혼동행렬, Accuracy, Recall, Precision, F1-score"
tags: [혼동행렬, Accuracy, Recall, Precision, F1-score]
comments: true
---





# ML 모델의 성능을 평가하는 지표(범주 분류 모델)

예전에 다른 포스팅에 쓴 적 있는 것 같지만 다시 정리해야 할 것 같아서 적어 본다.

 

### Confusion matrix(혼동 행렬)

|                      | Positive(Predicted) | Negative(Predicted) |
| -------------------- | ------------------- | ------------------- |
| **Positive(Actual)** | True Positive(TP)   | False Negative(FN)  |
| **Nagative(Actual)** | False Positive(FP)  | True Negative(TN)   |

주로 classification 모델의 성능을 평가하고 싶을 때 많이 사용된다. 



#### sklearn에서 확인

```python
from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_true, y_pred,labels=None, sample_weight=None, normalize=None))
```

#### heatmap

```python
import seaborn as sns

sns.heatmap(confusion_matrix, annot=True)
```



### Accuracy(정확도)

올바르게 예측된 데이터의 수를 전체 데이터의 수로 나눈 값


$$
Accuracy = \frac{TP+TN}{TP+TN+FP+FN}
$$


**장점** 간편?해서 가장 많이 사용된다

**단점**: 정확도 역설(Accuracy Paradox) 실제 정답이 한쪽으로 치우쳐 있다면 하나로 찍는 모델의 점수가 높게 나오게 된다.



### Recall(재현율)(=Sensitivity)

실제 True일 때 모델이 True로 예상한 비율. 맞다고 분류해야 하는 건수 중에서 분류기가 몇 개나 제대로 분류했는가.


$$
Recall = \frac{TP}{TP+FN}
$$
**장점:**  실제 데이터에 Negative 비율이 높아서 희박한 가능성으로 발생할 상황에 대한 분류 적합하다.

**단점:** 항상 True로 예상하는 모델의 recall은 1이다.



### Precision(정밀도)

모델이 True로 예상한 데이터 중 실제 True인 것의 비율. 분류기가 맞다고 분류한 건수 중에서 실제로 맞는 건수의 개수
$$
Precision = \frac{TP}{TP+FP}
$$
Recall과 trade-off 관계

**장점:** 실제 데이터에 Positive 비율이 높을 때 더 잘 맞는다.

**단점:**  항상 Negative로 예상하는 모델의 Precision은 1이다.



### F1 Score

Precision과 Recall의 조화평균을 낸 것

Precision과 Recall 둘 다 사용하기 때문에 두 지표의 단점을 보완한다.
$$
F1 score = 2*\frac{Precision*Recall}{Precision+Recall}
$$


### Sklearn에서 확인

```python
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score

print(accuracy_score(y_true, y_pred))
print(recall_score(y_true, y_pred))
print(precision_score(y_true, y_pred))
print(f1_score(y_true, y_pred))
```



[^ ]: 출처: https://eunsukimme.github.io/ml/2019/10/21/Accuracy-Recall-Precision-F1-score/
[^ ]: http://hleecaster.com/ml-accuracy-recall-precision-f1/