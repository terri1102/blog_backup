---
layout: post
title: "[EDA] Column과 Row Indexing"
date: 2021-01-16
category: [EDA]
DataScience: true
excerpt: "Dataframe에서 column, row 조작, indexing"
tags: [column, row, index, indexing]
comments: true
---

### Feature Engineering

df: row-observation, column-feature
tidy: one row, one feature

## 자료 형태(object, float, integer, string)

.dtypes: 자료 형태
Nan ->float타입

* Object to str : df2=d2_t.astype(float)

#시리즈 형태일 때 split,join 모두 매소드 앞에 str 붙이기 rp = column.str.join(str) 
#값이 float일 땐 split, join 없이 바로 mean 구할 수 있음

---

```python
pd.set_option('display.float_format', '{:,.1f}'.format)
pd.set_option('display.float_format', None) 
```



**groupby함수로 묶으면 df으로 나옴**

```python
region = df1.groupby('시도').sum()
```
**groupby 함수로 subset 만들기**##자꾸 틀리는 이유: sum 같은 거 안 붙여서

```python
groupedGenre = df.groupby('Genre')                                                     
genre = pd.DataFrame(groupedGenre.mean()[['NA_Sales', 'EU_Sales','JP_Sales','Other_Sales','Total_Sales']])
genre.sort_values(by='Total_Sales', ascending=False)
```

**데이터 프레임의 한 column을 array로 바꾸기**

```python
df[['column']].to_numpy()                                  #겹괄호 주의
```
**시리즈를 array로 바꾸기**
```python
s.to_numpy()
```
**df에서 crosstab으로 보고 싶은 column 뽑아서 index, column에 넣기**

```python
subset = pd.crosstab(index,column)
```

**row mean: axis =1**
```python
df['mean'] = df.mean(axis=1)
df.drop('Region', axis=1).apply(lambda x: x.mean(), axis=1)   #Region 열은 숫자가 아니어서 빼고 계산
```

**isin 함수로 특정 column의 값들 찾기**

```python
subset = df.loc[df['참조column'].isin(['A'])] #참조 column 안에 있는 A 값들어간 row만 subset으로 만듦
```

**isin 매서드를 이용한 불린 인덱싱**

```python
df[df.isin([5,2,50])]
```

**Contains('string')**

```python
sales['NA_Sales'].str.contains('\D', regex=True)
```

```python
ser[ser.str.contains('A|B')] #'A'나 'B'를 포함한 series 값 반환
```

**startswith((tuple))**

```python
ser[ser.str.startswith(('A', 'B',))]
```

**condition**

```python
condition = ( (df['column'] > 0) & (df['column'] < 10))
df_subset = df[condition]

df_subset
```



**sort_values정렬하기**

```python
top100 = df.sort_values(by='Total_Sales', ascending = False).head(100)
```

**Type cast**

```python
df['숫자만 있는 column'] = pd.to_numeric(df['숫자만 있는 column'])  #value에 숫자 아닌 문자 있으면 안 됨
```

**Typecast: Object to string**(Series!)

```python
############### Series를 typecast할 땐 'string'으로 해야함. 'str' 안 돼##########################
df['column'] = df['column'].astype('string')
```

**isin으로 특정 값만 빼고 subset 만들기(~tilde 사용)**

```python
subset = df.loc[~df['Year'].isin([3000])] #subset은 column 'Year'에서 3000을 제외한 row로만 구성됨
```

**데이터 매핑**

```python
#카테고리컬 데이터 매핑
d = {'John': 1, 'Mary': 2, 'Chris': 3, 'Anna': 4}
res['names'] = res['names'].map(d)
```

**소숫점 설정**

```python
#소숫점 첫째 자리까지 보이기
pd.set_option('display.float_format', '{:,.1f}'.format)

#기본 셋팅
pd.set_optiona('display.float_format', None)
```

**2x2 행렬일 때 한 값만 나오게 하는 거**

```python
np.corrcoef(a, b)[0,1].round(2) #소숫점 둘째자리
```

**결측치 nan으로 채움**

```python 
import numpy as np
df.loc[2,'당기순이익(비지배)']= np.nan
```

**분석**

```python
df.describe()
df.info()
```

**소숫점 자리 설정**

```python
df.round(2)
```

**숫자들에서 쉼표 제거하기: replace**

```python
testString = testString.replace(',', '')                          #str이 아닌 int엔 replace 쓸 수 없음
```

**숫자들에서 쉼표 제거하고 object-> float로 만들기**

```python
def tofloat(string):
  return float(string.replace(',', ''))
```

**숫자들에서 쉼표 제거 : split, join** 

```python
rev = df.loc[0,'매출액']
rev = rev.split(sep=',')                                          #리스트로 잘라짐                                             
a = ''.join(rev)                                                  #join 함수 형태가 특이
a = int(a)
```

**apply함수**

```python
def 함수()
df['column'] = df['column'].apply(함수)
```

**concat 매서드**

```python
df = pd.concat([df1, df2, df3, df4, df5, df6], axis = 1) #열 따라 붙임       
```

**merge 매서드**

```python
df_left.merge(df_right, how, on, sort, suffixes=())
#how{‘left’:왼쪽 df의 key만 사용, ‘right’:오른쪽 df key만, ‘outer’: 양 df의 key의 합집합, ‘inner’:양 df의 key의 교집합, ‘cross’:곱집합 생성}
#on: 겹치는 column
```

**melt**: tidy

```python
tidy = table.melt(id_vars = 'column', value_vars = ['A', 'B'])
```

**pivot_table**

```python
wide = tidy.pivot_table(index = 'row', columns ='column', values='value')
```



**lambda x**

```python
df.NA_Sales = df.NA_Sales.apply(lambda x: 0.001*float(x[:-1]) if 'K' in x else x).astype('string')
#이걸 함수로 만들려고 했는데 float은 iterable하지 않다고 자꾸 오류남. 모든 값이 Nan 되기도 하고, K가 안 떨어져서 float로 못 바꾸기도 하고.
```



---



## Column

**column이름 보기**

```python
for col in data.columns: 
    print(col) 
```

**새로운 column 만들기**

```python
#기존 column들 합쳐서 새로운 feature 만들기 
df['new column'] = df['previous column1'] +  df['previouw column2']
```

**column 삭제**

```python
df1 = df.drop(['삭제할 column'], axis = 1)                         #axis = 0 행 따라, axis = 1 열 따라 동작
```

**column 안에 일부 row 선택**

```python
data = df.loc[0:3,'column']                                        #'column' 열 안에 0~3 자리 열
```

**column 이름 변경**

```python
df.rename(columns ={'기존 column':' 새 column명'})
tidy1 = tidy1.rename(                              
   columns = {
        'variable': 'Feature', 
        'value': 'Value'})
```

**column 순서 변경**

```python
columnsTitles = ['abbrev', 'speeding', 'alcohol',	'not_distracted',	'no_previous',	'ins_premium',	'ins_losses', 'total']
df = df.reindex(columns=columnsTitles)
#다른 방법
df.columns = ['a','b','c']                                         # column 순서가 'a', 'b', 'c' 순서로 변경 
```

**특정 column 선택해서 데이터 변환**

```python

df.loc[:, ['a', 'b',	'c',	'd']] = df.loc[:, ['a', 'b',	'c',	'd']].round(1) #소숫점 한 자리까지만 보이기

df.loc[:, 'a':'d'] = df.loc[:,'a':'d'].str.replace(',', '')
```

**각 column별로 2의 자리에 있는 값 print** 

```python
# creating a list of dataframe columns 
clmn = list(col) 
  
for i in clmn: 
    # printing a third element of column 
    print(col[i][2]) 
```

**특정 column만 빼고 선택하기**

```python
Z = scaler.fit_transform(df.loc[:, df.columns != 'column'] )
```

**일부 column으로 새 df 만들기**

```python
rr = df_oh[['F3', 'F1_D', 'F1_N']] #대괄호 두 개 인거 주의
rr
```



---



## Index

### Indexing

```python
print(df.iloc[0])                   #0자리 열을 print
print(df.iloc[[0, 2]])              #0자리 행, 2자리 행 print        #[[]] 겹괄호 주의
print(df.iloc[0:2])                 #0~1자리 행 print
print(df.iloc[:, 0])                #0자리 열 print        
print(df.iloc[:, [0, 2]])           #0자리와 2자리 열 print          #[[]] 겹괄호 주의
print(df.iloc[:, 0:2])              #0~1자리 열 print
```

**index 선택하기**

```python
df.index[i]
```

**인덱스 가리기**

```python
from IPython.display import HTML                                        #html 이용, 예시 표처럼 깔끔하게 나옴
HTML(df_subset.to_html(index=False))
```

**인덱스 설정하기**

```python
df.set_index('column name')
```

**인덱스 축 이름 변경**

```python
df.rename_axis('names')
```

**row 범위선택**

```python
df[1:] #1번 row부터 나옴
df[1] #오류남. 하나의 row만 선택할 때는 iloc, loc 써야 할 듯
df[-1:] #마지막 row만 나옴
```



## Multiple index
```python
df1 = pd.DataFrame({'a': [art, art, art, science,science, history, history, history], 'b': [1, 1, 2, 1, 2, 1,2,1], 'c': [5,3,3,34,6, 12, 13,4]}
  a       b   c
0 art     1   5
1 art     1   3
2 art     2   3
3 science 1   34
4 science 2   6
5 history 1   12
6 history 2   13
7 history 1   4
```
**groupby 함수로 멀티 인덱스 만들기**
```python
df2 = df1.groupby(['a','b']).sum()
df2
a       b     c
art     1     8
        2     3
science 1     34
        2     6
history 1     16
        2     13

>>이렇게 하면 df2는 a,b 멀티 인덱스를 갖는 df가 됨
```

**Unstack(인덱스의 컬럼화):**
b 인덱스를 column name으로 보내서 멀티 column이 됨(멀티 column이 맞는 말인지는 모르겠음 )
```python
table = df2.unstack(level=-1, fill_value=None)
table
         c
b        1      2
a
art      8      3
science  34     6
history  16     13
```

**flattening hierarchical index in columns :column이 (b, c) 이런 벡터형태로 나와서 column level를 줄임**

```python
table.columns = table.columns.get_level_values(1)     #만약에 0이었으면 b아닌 c가 살아남았을 듯
table
b        1      2
a
art      8      3
science  34     6
history  16     13
>>정상적인 column으로 작동함
```

* 참고: https://data-make.tistory.com/126

**평범하게 멀티 인덱스 만들기**

```python
df1 = df.set_index(['state', 'color'], append=True)
df1
```



---

그외..

```python
#유일한 값 찾기
series.unique() #series 안에 있는 값들 종류별로 하나씩 나옴

#value별로 개수 세기 
series.value_counts(normalize, sort, ascending, bins, dropna)

#value 별 상대적 비율
series.value_counts(normalize=True)

#bins group별 값 세기
series.value_counts(bins=[0,1,2 등 값 종류], sort=True)

```

