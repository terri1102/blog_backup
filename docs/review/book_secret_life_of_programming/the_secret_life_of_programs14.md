---
layout: default
title: 한 권으로 읽는 컴퓨터 구조와 프로그래밍 14장
parent: 한 권으로 읽는 컴퓨터 구조와 프로그래밍
Grand_parent: Reviews
nav_order: 14
use_math: true

---





{:toc}

# 14장 세상을 바꾸는 기계 지능

미래를 열어가는 인공지능, 머신러닝, 빅데이터



**머신러닝의 발전 배경**

1) 기술적 발전으로 인해 저장장치의 크기는 늘고 가격은 저렴해졌음
2) 인터넷으로 인해 엄청난 양의 데이터를 쉽게 수집할 수 있게 됨



## 개요

**머신러닝** 

훈련 데이터를 프로그램에 넣고 프로그램에게 데이터의 의미를 말해주면 기계가 이를 습득하는 방법. 머신러닝 시스템은 인간의 자율 신경계의 기능과 같다. 현재 머신러닝은 인식(recognition)을 잘 처리하지만, 어떤 행위를 처리하는 수준은 인식에 비해서는 떨어진다.(데이터를 분류하는 등의 인식은 잘 해도, 행위가 주어졌을 때 여기에 대처하는 능력은 떨어진다는 의미인듯)



## 머신러닝

### 베이즈

**베이즈 정리**

두 확률 변수의 사전 확률(P(H))과 사후 확률(P(H|E)) 사이의 관계를 나타내는 정리
$$
P(H|E)= \frac{P(E|H)P(H)} {P(E)}
$$
예시) 메시지 100개에서 추출한 단어들의 백분율

| 단어      | 스팸 메시지 백분율 | 스팸이 아닌 메시지 백분율 |
| --------- | ------------------ | ------------------------- |
| meatloaf  | 80                 | 0                         |
| hamburger | 75                 | 5                         |
| catnip    | 0                  | 70                        |
| onion     | 68                 | 0                         |
| mousies   | 1                  | 67                        |
| the       | 99                 | 98                        |
| and       | 97                 | 99                        |

'hamburger and onion'이라는 문구가 있을 때 각 단어가 스팸에 속할 확률은 각각 75, 97, 68%이고 스팸이 아닌 메시지에 속하는 확률은 5, 97, 0%이다. 이때 이 메시지가 스팸에 속하거나 속하지 않을 확률은 아래의 결합확률과 같다. 
$$
p_{결합} = \frac{p_o p_1 p_2 ... p_n}{p_0 p_1 p_2 ... p_n + (1- p_0)(1-p_2)...(1-p_n)}
$$


나이브 베이즈 분류(Naive Bayes classifier) : '나이브'라는 의미는 주사위를 굴릴 때처럼 각 사건이 서로 관련되어 있지 않은 독립적인 사건이라는 뜻이다. 베이즈 정리에 따라 A일 때와 B일 때의 확률을(이진 분류 말고 멀티 클래스 분류도 가능함) 구한 후 더 높은 확률이 나오는 쪽으로 분류한다.



### 가우스

가우스 분포는 정규 분포(normal distribution)라고도 하며 어떤 현상을 관찰한 결과가 보통 종모양 곡선에 들어맞는다. 농구 선수의 평균 신장을 mu라고 할 때 선수 중 68%는 평균에서 표준 편차, 즉 theta 안에 들어가며 95%는 2 theta 안에 들어간다. 샘플 숫자가 늘어나면 어느 한 선수의 키가 알려주는 내용이 거의 없으므로 키의 분포도 종모양 곡선에 더 가까워진다. 잘 정의된 모집단(population)에서 주의 깊게 채취한 샘플을 사용해 분포를 얻으면 전체 분포를 추정할 수 있다.



**가우시안 블러(Gaussian blur)**

 물체의 테두리를 찾기 위해 우리는 사진을 약간 흐릿하게 만들어서 세세한 부분을 흐리게 만든다. 가우스 분포의 곡선을 mu를 중심으로 회전시켜서 3차원 버전을 만든다. 이 3차원 가우스 분포를 이미지로 끌어가서 mu를 각 픽셀의 중심에 차례로 일치시킨다. 이제 곡면 아래에 있는 픽셀의 값과 곡면의 값을 곱한 결과를 모두 더해서 중심 픽셀의 값으로 만든다. 이런 과정을 수학에서는 컨볼루션이라고 부르며, 가중치 배열을 커널(kernel)이나 컨볼루션 커널이라고 부른다.

![gaussian_distribution_3d](https://miro.medium.com/max/683/1*9rdkuNxjx5bCACeo1CVjpA.png)

이미지를 밝기 = f(x,y)라는 수학 함수의 결과로 생각할 수 있다. 이 함수의 값은 각 좌표 점상의 픽셀 밝기다. 이 함수는 이산적이기 때문에 x,y는 정수값이어야 한다. 비슷한 방식으로 컨볼루션 커널을 값이 가중치 = g(x,y)라는 작은 이미지라고 생각할 수 있다. 따라서 어떤 점에 대해 컨볼루션을 수행하는 과정은 커널이 덮는 영역에 속한 모든 점을 순회하면서 커널의 가중치를 곱한 다음에 다 더하는 방식으로 이뤄진다.



### 소벨

미적분을 이용해서 밝기 변화를 측정한 다음에 실제 테두리를 찾아 볼 수 있다. 어떤 함수의 도함수(derivative)는 함수가 만들어내는 곡선의 기울기다. 한 픽셀과 바로 오른쪽 픽셀 사이에 밝기가 변한다면 밝기 변화 공식은 밝기 =  f(x+1, y) - f(x,y)이다. 이를 이용해서 밝기 변화를 측정하되 픽셀 중간에서도 변화가 생길 수 있게 가우스 필터 대신 종모양 곡선의 1차 도함수를 사용한다. 가우시안 블러 커널에서 했던 것과 빗스하게 여기서도 가우스 곡선의 기울기에서 얻은 값을 바탕으로 소벨 테두리 감지 커널을 생성한다. 이 커널을 적용하면 각 픽셀마다 한 쌍의 증감률(gradient) G_x와 G_y를 얻는다. 증감률을 경사도로 생각할 수 있다. 직교 좌표 각 축 방향에 대한 증감률을 알고 있으므로, 삼각함수를 사용해 이를 극좌표로 변환하면 규모(magnitude)와 방향(direction)을 알 수 있다. 증감률 규모는 테두리가 얼마나 강한지를 말하며 방향은 테두리의 방위를 뜻한다.

![sobel operator](https://ars.els-cdn.com/content/image/3-s2.0-B9780123814203000072-f07-02-9780123814203.jpg)



### 캐니

캐니는 소벨의 결과를 개선해서 테두리 감지를 개선했다. 비최댓값 억제(nonmaximum suppression)을 이용해서 테두리를 가늘게 하는(edge thinning) 기법을 사용했다. 비최댓값 억제는 각 픽셀의 증감률 규모를 증감률 방향에 있는 이웃 픽셀과 비교해서 만약 가운데 픽셀의 규모가 주변 픽셀의 규모보다 크면 값을 유지하고, 작으면 0으로 만든다. 비최댓값 억제는 이미지에서 테두리를 많이 만들어 낸다. 캐니 처리의 마지막 단계는 이력(hysteresis)를 활용해서 약한 테두리를 억제하고 강한 테두리를 남기는 것이다. 비최댓값 억제 결과를 스캔하면서 테두리 픽셀을 찾되, 증감률 규모가 상단 문턱값보다 큰 픽셀만 찾고 이를 최종 테두리 픽셀로 판정한다.





### 특성 추출

**이미지 인식 파이프라인**

1. 흐리게 하기
2. 테두리 감지
3. 비최댓값 억제
4. 이력을 활용한 테두리 추적
5. 특성 추출
6. 분류



### 인공 신경망

인공지능 분야에서 인간의 지능을 흉내내기 위해 뉴런의 구조를 모방한 인공신경망을 만들었다. 각 수상돌기는 입력을 받아서 가중치(weight)로 곱한 다음, 모든 가중치가 곱해진 값을 더한다. 전체를 더한 값이 활동 전위(action potential)보다 낮으면 출력이 false이고, 높으면 true여서 뉴런이 출력을 활성화(fire)된다. 최초론 인공 뉴런을 만들려는 시도는 프랭크 로젠블랏의 퍼센트론이었다.

시그모이드 뉴런의 탄생과 함께 가중치를 알아내는 방법을 생각해냈다. 시그모이드 뉴런에서는 역전파 기법을 사용해 신경망의 가중치를 결정할 수 있다. 역전파로 구한 입력에 대한 출력을 관찰할 때 예상 출력값에서 실제 출력값을 뺀 값인 오류 함수를 계산할 수 있으며, 이를 0으로 만드는 것을 목표로 하여 가중치를 조정한다. 가중치 조정은 경사하강 알고리즘을 이용해서 이뤄진다. 

신경망의 핵심은 엄청난 양의 입력 데이터를 가지고 원하는 대로 입력을 기술하는 훨씬 적은 양의 출력으로 변환하도록 신경망을 훈련시킬 수 있다. 이를 차원 수 축소(reducing dimensionality)라고 표현한다.



## 인공지능

유전 알고리즘(genetic algorithm) : 진화를 흉내낸 방법

1. 무작위로 셀을 만든다.

2. 목표로부터 각 셀의 적합도를 계산한다.
3. 성능이 가장 나쁜 셀을 죽여 없앤다.
4. 가장 성능이 좋은 두 셀을 사용해 새로운 셀을 만든다.
5. 셀 중 하나가 목표에 도달할 때까지 이 단계를 반복한다.

