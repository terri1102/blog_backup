# Chapter1 빅데이터의 기초 지식 1

## 1-1 [배경] 빅데이터의 정착

## 1-2 빅데이터 시대의 데이터 분석 기반





# Chapter 2 빅데이터의 탐색

## 2-1 크로스 집계의 기본



## 2-2 열 지향 스토리지에 의한 고속화

MPP 데이터베이스



## 2-3 애드 훅 분석과 시각화 도구

대시보드 도구와 BI도구의 차이는 그다지 엄밀하지 않다. 전자는 새로운 그래프를 쉽게 추가할 수 있는 것이 중시된다면, 후자는 보다 대화형 데이터 탐색이 중요시된다.

대시보드 예: Redash, Superset, Kibana



## 2-4 데이터마트의 기본 구조

데이터 마트와 OLAP

OLAP: 다차원 모델의 데이터 구조를 MDX 등의 쿼리 언어로 집계

순서: 비정규화 테이블 준비 -> 다차원 모델에 의해 추상화

다차원 모델은 칼럼을 '디멘전'과 '측정값'으로 분류

측정값: 숫자 데이터와 그 집계 방법을 정의하는 것이 측정값

디멘전: 크로스 집계에 있어서의 행과 열을 이용하는 것이 디멘전



## 3-1 대규모 분산처리의 프레임워크

분산 시스템의 구성 요소: HDFS, YARN, MapReduce

HDFS: 분산 파일 시스템

YARN: 리소스 관리자

MapReduce or Spark: 분산 데이터 처리의 기반



Spark: 인 메모리 형의 고속 데이터 처리. MapReduce를 대체함



디스크에 쓰기 vs 메모리상 에서 실시

---



웹서버의 액세스 로그의 예

```python
#data 'NASA-HTTP- The internet Traffic Archive'
http://ita.ee.lbl.gov/html/contrib/NASA-HTTP.html


import re
import pandas as pd

#로그의 각 행에 매치하는 정규표현
pattern = re.compile('^\S+ \S+ \S+ \[(.*)\] "(.*)" (\S+) (\S+)$')

#정규표현으로 파싱하는 함수(일치하지 않으면 버림)
def parse_access_log(path):
    for line in open(path):
        for m in pattern.finditer(line):
            yield m.groups()

#로그 파일을 읽어서 데이터 프레임으로 변환
columns = ['time','request','status','bytes']
pd.DataFrame(parse_access_log('access.log'),columns=columns)
```

