---
layout: default
title: Spark
date: 2021-06-04
parent: Database
nav_order: 4
comments: true
---



# hadoop

HDFS: 분산파일 시스템. 

다양한 어플리케이션을 돌릴 때 클러스터 매니지먼트를 해주는게 yarn 





# spark

### 아파치 스파크: 

빅데이터처리를 위한 오픈소스 병렬분산처리 플랫폼

스파크는 데이터소스로부터 데이터를 읽어 들인 뒤 스토리지 I/O와 네트워크 I/O를 최소화하도록 처리한다. 따라서 스파크는 동일한 데이터에 대한 변환처리가 연속으로 이루어지는 경우와 머신러닝처럼 결과셋을 여러 번 반복해 처리하는 경우에 적합하다. 또한, 지연이 작게 동작하는 특성을 이용해 스트림처리를 할 수도 있다.

### 스파크 구조

다양한 데이터 소스-스파크 엔진(스파크 코어)-용도별 라이브러리(스파크SQL, 스파크 스트리밍, MLib, 그래프X)

![그림1-1]

## 스파크의 특징

1. 반복처리와 연속으로 이루어지는 변환처리의 고속화

맵리듀스와 비교

맵리듀스는 기본적으로 입력 데이터를 스토리지에서 읽고 복수의 머신에서 분산처리를 수행한 후 그 결과를 스토리지에 보존한다. 이 처리가 한 번에 끝나지 않을 경우 데이터가 플로flow 형식으로 처리되어 읽기->분산처리->보존을 반복 수행한다.

맵리듀스를 활용한 데이터처리 플로는 각 처리의 중간 결과가 항상 스토리지에 보존되므로 데이터 크기가 커져도 문제없이 작동하며, 시스템 장애가 발생해도 비교적 쉽게 복구되는 만큼 강력한 처리 모델이라고 할 수 있다. 하지만 특정 데이터의 부분집합에 대해 여러 번 처리하는 애플리케이션은 맵리듀스로 효율적인 처리가 어렵다.

맵리듀스가 연속으로 이루어지는 처리를 할 때 매번 모든 데이터를 디스크로 출력하는 것과는 달리, 스파크는 연속으로 이루어지는 처리에서 매번 불필요한 디스크와 네트워크 I/O가 발생하지 않도록 처리한다. 연속으로 이루어지는 처리 전체를 검토한 뒤에 그에 맞는 최적화 처리를 끼워넣는 방식으로 설계하여 맵리듀스보다 고속으로 처리할 수 있고 완전히 대체할 수 있다고 한다.



2.. 시행착오에 적합한 환경 제공

한 대의 서버에서 처리할 수 있는 용량을 넘어서는 데이터셋에 대해서는 스케일아웃과 같은 방법을 선택하고 여러 대의 머신으로 구성해 병렬분산처리를 수행할 필요가 있다.

스파크는 병렬 분산 환경을 의식하지 않고 처리를 기술할 수 있는 것을 목표로 한다. 스파크에는 데이터셋을 추상적으로 다루기 위한 RDD(Resilient Distributed Dataset, 내결함성 분산 데이터셋)라는 데이터셋이 있고, RDD가 제공하는 API로 변환을 기술하기만 하면 처리되게끔 구현되었다.

interactive CLI

3. 서로 다른 처리를 통합해 이용할 수 있는 환경

배치처리, 스트림처리, SQL처리, 머신러닝 그리고 그래프처리와 같은 서로 다른 형태의 애플리케이션을 하나의 환경에서 통합적으로 다룰 수 있는 점도 스파크의 큰 특징 중 하나.

---

# Chapter 2 스파크의 처리 모델

## 스파크의 기본적인 자료구조 RDD

RDD는 대량의 데이터를 요소로 가지는 분산 컬렉션이다. 거대한 배열과 리스트 등의 자료구조를 생각해보기. RDD는 여러 머신으로 구성된 클러스터 환경에서의 분산처리를 전제로 설계되었고, 내부는 파티션이라는 단위로 나뉜다. 스파크에서는 이 파티션이 분산처리 단위이다. RDD를 파티션 단위로 여러 머신에서 처리하므로 한 대의 머신으로 처리할 수 있는 것보다 더 큰 데이터를 다룰 수 있다.

### RDD 다루기

RDD에는 변환과 액션 두 종류의 처리르 적용할 수 있음

### 변환(Transformation) 

변환이란 RDD를 가공하고 그 결과 새로운 RDD를 얻는 처리다. 변환처리 후의 RDD가 가지는 요소는 변환처리 전의 RDD에 들어있던 요소를 가공하거나 필터링해 생성된다.

변환은 다시 두 종류로 구분할 수 있는데, 

1) 첫 번째는 변환처리 전의 RDD가 가지는 요소를 같은 RDD의 다른 요소들과 관계없이 처리할 수 있는 종류다. 

**filter:**요소를 필터링한다.

**map:** 각 요소에 동일한 처리를 적용한다.

**flatmap:** 각 요소에 동일한 처리를 적용하고 여러 개의 요소를 생성한다.

**zip:** 파티션 수가 같고, 파티션에 있는 요소의 수도 같은 두 개의 RDD를 조합해 한쪽의 요소 값을 키로, 다른 한쪽의 요소 값을 밸류로 가지는 쌍key-value pair를 만든다.

2) 두 번째 종류는 변환 전의 RDD가 가지는 요소를 같은 RDD의 다른 요소와 함께 처리하는 변환이다. 그 변환 대상은 키와 밸류의 쌍을 요소로 가지는 RDD다. 같은 키를 가지는 요소를 한데 모아 처리하는데, 이때 같은 키를 가지는 요소가 전부 같은 파티션에 있어야 한다. 스파크는 파티션 단위로 독립해 분산처리하기 때문이다. 이떄 서로 다른 파티션에 있는 같은 키를 가지는 요소의 자리를 바꾸는 것을 **셔플**이라고 한다.

셔플은 변환하기 전의 RDD 요소를, 변환 후에 키를 기준으로 각 파티션에 배분한다. 따라서 셔플에 의해 같은 키를 가지는 요소가 같은 파티션에 있도록 보증할 수 있다. 이러한 종류의 변환에는 다음과 같은 것들이 있다.

**reduceByKey**: 같은 키를 가지는 요소를 집약처리(aggregation)

**join**: 두 개의 RDD에서 같은 키를 가지는 요소끼리 조인한다.

### 액션(Action)

변환이 RDD로부터 다른 RDD를 얻는 '데이터 가공'에 해당하는 조작이라면, 액션은 RDD 내용을 바탕으로 데이터를 가공하지 않고 원하는 결과를 얻는 조작이다.

**saveAsTextFile**: RDD의 내용을 파일로 출력한다. 같은 디렉터리에 파티션 단위로 각 파일을 따로 출력한다.

**count**: RDD의 요소 수를 센다. 결과를 얻을 때 파티션 단위로 카운팅된 값을 합한다.



그 외에도 많은 변환과 액션이 있다.



## 스파크 분산처리 환경

### 클러스터 환경 개요

스파크는 여러 머신으로 구성된 클러스터 환경에서의 동작을 전제로 한 분산처리 플랫폼이다. 스파크를 포함해 클러스터 환경에서 처리를 시행하는 일반적인 시스템은 클러스터 내의 계산 리소스를 관리하는 기능이 필요하다. 그러한 기능을 제공하는 시스템을 '클러스터 관리 시스템'이라고 한다. 스파크는 YARN, Mesos, Spark Standalone 세 종류의 클러스터 관리 시스템을 지원한다.

클러스터 관리 시스템 하에서 각 머신은 마스터 노드 또는 워커 노드로 동작한다. 마스터 노드는 클러스터 내의 계산 리소스를 집중하며 관리 역할을 담당한다. 한편 워커 노드는 CPU 코어와 메모리 등의 계산 리소스를 제공하고 할당된 처리를 실행한다. 마스터 노드와 복수의 워커 노드로 구성된 클러스터 환경에서는 다음과 같은 프로세스로 분산처리가 이루어진다.

1) 애플리케이션 배포와 계산 리소스 요구

스파크로 분산처리할 때 RDD 생성과 일련의 변환으로 구성된 스파크 애플리케이션을 클라이언트가 클러스터에 배포deploy한다. 

클라이언트는 애플리케이션을 배포함과 동시에 애플리케이션 실행에 필요한 이그제큐터executor의 스펙을 지정한다. 이그제큐터란 워커 노드에서 구동하여 스파크 애플리케이션을 분산처리하는 프로세스를 말한다. 이그제큐터의 스펙으로는 CPU 코어 수의 할당량과 메모리 할당량, 클러스터 내에서 구동할 이그제큐터 수를 지정할 수 있다.

2)클러스터 내 계산 리소스 확보

클러스터에 애플리케이션이 배포되면, 마스터 노드는 각 워커 노드의 이용 가능한 리소스양과 클라이언트가 요청하는 이그제큐터 스펙을 고려하여 하나 이상의 워커 노드에 이그제큐터의 구동을 요구한다.

3)드라이버 프로그램 구동

클러스터 내에 리소스가 확보됨과 동시에 '드라이버 프로그램'이 구동한다. 드라이버 프로그램이란 사용자에 의해 정의되는 스파크 애플리케이션의 엔트리 포인트(함수 같은 실행포인트)가 되는 프로그램이다. 사용자가 기술한 RDD의 생성 및 변환 로직을 이용해 애플리케이션을 제어하는 역할을 담당.

드라이버 프로그램은 배포 시점의 옵션에 따라 클라이언트에서 구동할지 워커 노드에서 구동할지를 결정할 수 있다.

4)테스크 스케줄링과 실행

스파크 애플리케이션에서 RDD 생성부터 액션 적용까지를 통틀어 잡job이라는 단위로 처리한다. 잡은 드라이버 프로그램에 포함되는 스케줄러에 의해 이그제큐터가 처리 가능한 테스크task라는 단위로 분할되며, 그 실행이 스케줄링된다. 테스크는 파티션 단위로 데이터를 로드하고 변환과 액션을 적용하는 처리단위이기도 하다. 따라서 이그제큐터가 각 태스크를 처리함으로써 RDD 전체가 분산처리되는 것이다.



**드라이버 프로그램** 스파크 애플리케이션의 동작 제어.드라이버 프로그램에서 RDD를 생성하거나 변환할 수 있는 요인은 RDD의 지연 평가에 있다. 드라이버 프로그램에서 RDD에 데이터 로드와 변환, 액션의 적용을 선언할 때 실제 처리는 드라이버 프로그램에서 이루어지지 않으며 잡 형태로 클러스터에서 실행된다. 그리고 실행시점은 드라이버 프로그램에서 액션의 적용이 선언될 때까지 지연된다.



**테스크 스케줄링**: RDD의 생성과 로드는 지연 평가lazy evaluation되므로, RDD가 데이터를 가진 상태가 되는 것(인스턴스화)은 클러스터를 처리할 때다. 드라이버 프로그램에서 생성된 RDD에는 테스크 작성과 스케줄링에 필요한 정보가 포함된다.

드라이버 프로그램에서 RDD에 대한 액션 적용이 선언되면, 해당 드라이버 프로그램에서 동작하는 스케줄러가 이 정보를 바탕으로 변환의 전체적인 흐름을 해석한다. 그리고 이그제큐터 간의 네트워크 통신과 I/O 부하가 가능한 한 작아지도록 태스크를 구성하는 등 스케줄링에 도움을 준다.

스파크에서는 이그제큐터에 장애가 발생하는 이유로 테스크 실행에 실패하면 다른 이그제큐터로 재실행된다. 이 경우에도 테스크 내용을 바탕으로 파티션을 순서대로 인스턴스화해 처리한다. 스파크는 이것을 재계산recompute이라 한다.

RDD는 불변이므로(데이터소스도 불변) 재계산에 의해 동일한 변환이나 액션이 적용되더라도 같은 결과를 얻을 수 있다.

### RDD 영속화

이그제큐터는 태스크 처리를 끝낼 떄, 처리 과정에서 생성된 파티션 인스턴스를 여속화하는 경우가 있다. 스파크에서는 RDD가 다음 조건 중 어느 하나라도 만족하면 영속화된다.

* 셔플이 발생하는 변환을 실행하기 직전의 RDD
* 사용자에 의해서 명시적으로 영속화가 선언된 RDD

만약 RDD의 파티션이 하나라도 영속화되지 않으면, 해당 RDD 전체가 영속화되지 않은 것으로 간주된다. 애플리케이션에서 RDD를 재사용할 경우에는 해당 태스크를 다시 한번 스케줄링해 클러스터 환경에서 다시 데이터를 로드하고 변환해야 하므로 비효율적이다. 한편, RDD의 파티션이 전부 영속화되면 RDD 자체가 영속화된 것으로 간주한다. RDD가 영속화되면, 해당 RDD의 인스턴스를 다시 만들기 위해 변환 대상 RDD를 인스턴스화 하거나 데이터를 로드하는 등의 처리를 생략할 수 있다.

---

# Chapter 3 스파크 설치하기

| 호스트명     | 역할 | 설명 |
| ------------ | ---- | ---- |
| spark-client |클라이언트|애플리케이션을 구동하는 클라이언트(단일 머신 환경에서는 이 호스트만을 이용. )|
|spark-client|마스터 노드| 클러스터 내의 리소스를 집중관리|
|spark-worker00|워커 노드|CPU 코어와 메모리 등 애플리케이션 실행에 필요한 리소스를 제공|

![그림3-1]

단일 머신 환경에서는 스파크의 데이터 소스로서 주로 로컬 파일 시스템을 이용. 클러스터 환경에서는 하둡의 클러스터 관리 시스템인 YARN을 이용하고, 스파크 데이터소스로는 주로 분산 파일시스템인 HDFS를 이용한다. 이 HDFS와 YARN은 spark-master와 spark-worker00~spark-worker03에 설치한다.



스파크 설치

java :openjdk version "1.8.0_292"

spark: spark-2.4.8-bin-hadoop2.7

```bash
# wget https://mirror.navercorp.com/apache/spark/spark-2.4.8/spark-2.4.8-bin-hadoop2.7.tgz
```



## 3.3.1 HDFS란 무엇인가

HDFS는 하둡 분산 파일시스템으로, 클러스터 환경에서의 작동을 전제로 설계되었다. NameNode라고 하는 마스터 노드와 DataNode라고 하는 복수의 워커 노드로 구성된다. 

* Name Node: HDFS의 마스터 노드에 해당. HDFS상에 보존되는 파일의 메타데이터와 보존된 파일의 분할된 조각(블록)이 어떤 DataNode에서 관리되는지 등의 정보를 관리한다.
* DataNode: HDFS의 워커 노드를 말한다. HDFS상에 보존된 파일의 블록을 관리한다.

HDFS는 파일을 블록단위로 분할하고, 각 블록을 복수의 DataNode에 분산해 저장함으로써 수 기가바이트에서 수 페타바이트에 달하는 거대한 데이터를 보존할 수 있다. 또한 일반적인 파일시스템과 비교해 기본 블록 크기가 128mb로 커서 거대한 파일을 다룰 때 높은 I/O 처리량을 실현할 수 있다.

HDFS는 슬레이브 노드인 DataNode를 추가함으로써 I/O처리량과 저장 용량을 스케일아웃할 수 있다. 또 블록을 기본3개의 DataNode에 레플리카하여 보존함으로써 일부 슬레이브 노드가 고장을 일으키더라도 데이터 손실이 없도록 설계됨.

**YARN**

하둡의 클러스터 관리 시스템. 스파크를 비롯한 각종 분산처리 프레임워크 작동하는 환경 관리. YARN은 Resource Manager라고 불리는 마스터 노드와 NodeManager라고 하는 여러 개의 워커 노드로 구성된다.

ResourceManager: 클러스터 전체의 계산 리소스를 관리하고, 클라이언트가 요구한 리소스를 NodeManager로부터 확보하도록 스케줄링한다. 스파크에서의 ResourceManager는 요청된 이그제큐터 개수와 CPU 코어의 수, 메모리양에 따라 이그제큐터를 하나 이상의 NodeManager로부터 확보하는 역할을 담당.

Node Manager: 클러스터 전체의 계산 리소스를 관리하는 ResourceManager와는 달리, 자신이 설치된 머신(노드)의 계산리소스만을 관리한다. ResourceManager로부터 받은 요청에 따라, 필요한 계산 리소스를 확보한 '컨테이너'라는 애플리케이션의 실행 환경을 제공한다. 요청된 컨테이너의 개수에 따라서 복수의 NodeManager로부터 컨테이너를 확보해 분산처리한다. 스파크의 경우 이그제큐터가 NodeManager로부터 확보된 컨테이너상에서 작동.(스파크의 이그제큐터는 YARN의 컨테이너)



---



## 더 알아보기

'Estimating Financial Risk with Spark', Sandy Ryza, Cloudera, Spark Summit 2015 East



## Reference

아파치 스파크 입문, 사루타 고스케, 한빛 미디어
