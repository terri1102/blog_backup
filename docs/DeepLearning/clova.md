---
layout: default
title: Image Classification Pipeline
date: 2021-05-23
parent: Deep Learning
nav_order: 5
comments: true
---

fddd

# HYPER CLOVA

![hyperclova]()

GPT-3의 한국어 데이터 보다 6500배 더 큰 한국어 모델

지난 12월 슈퍼컴퓨터 도입

앞으로 CLOVA가 제공할 기술들은...

물건의 태그만으로 홍보문구 제작, 이미지 간단한 설명



네이버 AI 윤리지침: 첨단의 AI 기술을 누구나 사용하는 일상의 도구로 만들겠다.

---

![1부]()

지난 반년간의 HYPERCLOVA 연구와 앞으로의 방향

최초의 한국어 초거대 모델

![데이터크기]()

5600억 토큰의 한국어 데이터 학습

700페타플롭스 국내 최고 슈퍼컴퓨터



모델을 크게 만들 수 있는 이유: 비지도 학습

지도학습은 일일이 레이블링을 했어야 했음. 하지만 비지도학습, 준지도학습은 데이터를 그대로 학습에 이용할 수 있게 됨.



큰 모델이 작은 모델보다 오히려 더 효율적일 수 있다! 데이터의 양이 무한하다는 가정하에엇 



클로바 자랑...

대단한 이유: 연결된 대화가 가능하다는 것. 문맥을 기억한다는 것. 사용자의 감정을 파악



2. 창작을 도와주는 글쓰기

다양한 예시 문장 만들기, 문체 변경

신조어를 사용한 문장도 만들 수 있다.



3. 정보 요약

여러 문서에서 여러 의견을 요약해서 정리해줌.



4. 데이터 생성

사용자의 발화 의도마다 코퍼스를 구축해서 AI 학습하는데 

데이터를 구축할 수 있음.



![하이퍼클로바기능]()

드는 생각은 이미 언어 모델들이 수행하고 있는 태스크들을 엄청난 크기의 데이터를 학습함으로써 더 잘 수행할 수 있다는 것 같다. 

![하이퍼클로바생태계]()



앞으로 언어 뿐 아니라 다양한 모델리티로 확장할 예정

---

![2부]()

슈퍼컴퓨터



---

# NLP

![3부]()

데이터의 구축시 목표: 1.다양한 내용 2. 범용의 구성 3. 양질의 정보 4. 충분한 크기



모두의 말뭉치, 전문 지식

![데이터의구성]()



개인정보 보호: 검색 가능한 정보들 중 아이디나 전화번호 등 개인정보는 제거 or 비식별화

문서의 양식 유지: html 파싱

지식인 : 질문 1에 답변 1로

문서 정보에 메타정보 추가: 대화문, 출처 추가



양질의 정보를 선별. 상위 품질의 정보 중에서도 웹 페이지의 핵심정보만 참고함. 정보 가치가 일정 수준 이상인 영역만 선별해서 포함시킴

![저품질필터링]()



5600억 토큰:ㅋㅋ엄청 강조하네

GPT 3 대비 한국어 데이터 양의 6500배



욕설 순화



텍스트 위주 말고 멀티모달리티 데이터 구축을 준비하고 있음



---

![4부]()

구글 등 공개된 오픈소스 모델만을 그냥 가져다 쓸 수 없다!

글로벌 AI 리더가 되기 위해서는ㅋㅋ

AI 연구의트랜드: BIG -학습 데이터, 인프라, 연구진 규모

![ai연구스펙트럼]()

해외 협력 : 글로벌 AI 연구 생태계 구축



언어모델의 문제: hallucination

넣지 않은 데이터가 나오는 거



Cycle gan,

언어모델 구축엔 벤치마크 데이터가 중요하다: 한국어는 부족한 상황

KLUE 프로젝트 진행 중 곧 공개할 예정

---

네이버 AI 윤리 준칙

1) 사람을 위한 AI 개발

2) 다양성의 존중

3) 합리적인 설명과 편리성의 조화

4) 



---

![part2]()



점점 인간이 같이 안 일하고 기술의 도움으로 혼자서 이것저것 다 하게 되는 느낌.



# HYPER CLOVA 한국어 언어 모델

gpt 3 영어 92.7 % 사실상 영어 전용 모델. 한국어 생성 능력이 매우 제한적

![데이터처리파이프라인]

![언어전처리]

일주일이 걸림->하둡으로 

![모델크기증가]

각각의 gpu에서 연산 후

최종적으로 파라미터 정할 떄 이를 합침



waterfall 부분에서 급증.

몇몇 예시만을 위한 in context 만으로도 down stream task에서 준수한 성능



---

## 한국어에 적합한 토크나이저

HYPERCLOVA가 한국어를 읽는 방법



기계가 글을 이해하려면

문장을 어떠한 단위로 끊어읽는 능력이 필요



서브워드 토크나이저

![서브워드]

BPE사용: 자주 등장하는 문자열을 하나의 문자열로 병합해가면서 어휘집합을 구성해나가는 것



언어모델을 위한 서브워드 토크나이저



Morpheme aware byte level BPE tokenizer로 문장 처리함



---

# 언어모델 평가지표

![생성판별모델]



---

쉽게 만드는 AI

HyperCLOVA Studio

![기존ai프로세스]

![ai개발자들]

