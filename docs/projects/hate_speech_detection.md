---
layout: default
title: Hate speech detection 프로젝트
parent: Projects
has_children : true
nav_order: 3
---


## 프로젝트 배경
혐오발언을 분류할 때 기존의 모델들을 그 타겟 문장만을 이용한 분류를 하는 경우가 대부분이지만, 타겟 문장에 혐오 발언이 없더라도 그 앞 문장의 문맥에 따라 혐오 발언인 경우도 있을 수 있기 때문에 이번 프로젝트 과제로 주어진 context를 고려한 혐오 문장 분류를 선정


## 발견한 문제
* 클래스 불균형
* 느린 Inference Time
* 분산 훈련 후 모델 load 문제
* Tokenizer의 truncation 문제

## 해결한 문제
* 클래스 불균형: 다른 데이터셋을 여러 개 결합하여 사용
* Inference Time 개선: tokenizer를 빠른 것으로 사용
* 분산 훈련 후 모델 load: load_state_dict 옵션 조절


## 해결 못한 문제
* Tokenizer 문제
정확하게 무슨 문제인지는 모르겠는데, 문장을 tokenize할 때  자동으로 길이 조절이 안 되어서 모델을 train할 수 없었는데, 직접 character 개수로 잘라서 사용하니까 모델이 돌아갔다. 이는 근본적인 해결이 아닌 것 같고 모델 성능이 이상한 것에 영향을 준 것 같다.

* 과적합 문제
데이터가 적어서 그런지 과적합되어서 모델 성능이 test 정확도: 0.99, f1 score: 0.99 이런식으로 나온다. 클래스 하나로 찍는 모델은 아니지만, 내가 구축한 데이터셋이 아닌 다른 데이터셋을 사용해서 테스트를 해봐야 할 것 같다.

## 결과
[실험 1]

같은 조건으로 albert-base-v2, distilbert-base-uncased 비교한 결과 distilbert가 더 성능이 좋고, 빨랐다.


[실험 2]
Distilbert-base-uncased로 두 가지의 데이터셋을 나눠서 훈련했는데, 평가 척도 상의 차이는 미미했고, context를 고려하는데 더 좋은 성능을 보일 것이라고 생각했던 데이터셋으로 훈련한 모델도 예측하는데 별 차이가 없었다.



## Timeline

#### Week1 - 2

데이터셋 탐색 및 여러 논문 읽기



#### Week 3

논문 읽기 및 모델 아키텍처 고민



#### Week 4 

모델링 및 경량화 & BentoML




## 회고

4주 내내 열심히 한 것 같긴한데, 프로젝트 진행 과정이 해보려고 하려던 것들을 많이 못해봐서 아쉽다. 특히 병렬 학습한 모델의 호환 등 호환이 안 되는 문제를 많이 겪어서 어려움이 많았는데, 많이 경험해보는 것이 중요할 것 같다. 데이터셋을 구할 때도 요청을 보내도 답이 없기도 하고, 원하는 결과를 내기 위한 데이터 수집이 어려웠기 때문에 앞으로도 데이터 잘 찾고 가공하는 연습을 많이 해봐야 할 것 같다.



또한, 실제 모델을 서비스하는 입장이 되어 빠르고 가벼운 모델에 대해 고민해 볼 수 있어서 좋았다. 여태까지는 모델 정확도와 성능에 대해서만 생각해봤었는데, 때로는 모델 성능이 좀 낮아지더라도 경량화가 더 중요할 때도 있다는 것을 느꼈다. 



앞으로 개선해 보고 싶은 것은 더 가벼운 모델을 만들어 보는 것과, 다양한 데이터셋을 사용해 더 generalizable한 모델을 만들어 보는 것이다. 
